include "application"

akka.log-dead-letters-during-shutdown = false

rotakka {
  twittercrawling {
    # The number of TwitterCrawler-actors to start
    slaveCount = 1

    # The start date of the crawling time frame in dd-MM-yyyy
    startDate = "09-09-2019"

    # The end date of the crawling time frame in dd-MM-yyyy
    endDate = "10-09-2019"

    # The users which you want to crawl, seperated by comma if multiple. When extractUsers is true, these are
    # the entry points for crawling
    entryPointUsers = "guardian"

    # Wheter to extact new users from Tweets. Set this to false if you just want to crawl the specified users and not
    # additionally crawl the extracted users
    extractUsers = true

    # Whether to use the extracted proxies or not. Using them will slow down the system in exchange for stealth
    useProxies = false

    # The time which to wait on a dymanic page load. Set this accordingly to the quality of proxies you intend to use.
    dynamicContentWait = 500

    # The number of work packets (i.e. Twitter Advanced Search Links) which will be crawled with a single proxy
    # before changing to a new one
    requestPerProxy = 1000
  }

  proxychecking {
    # The number of ProxyChecker-actors to start
    slaveCount = 2

    # The maxium response time in millies which a proxy can have in order to be used by Rotakka
    # Proxies exceeding this value will be dropped
    maxiumResponseTime = 300
  }

  proxycrawling {
    # The number of ProxyCrawler-actors to start
    slaveCount = 1
  }

  graphstore {
    # number of graph store slaves per actor system
    # recommended to leave it at 1 to prevent storing multiple copies of the same shard on a single node
    slaveCount = 1

    # least common multiples are preferable to create even splits for up to n servers
    # we suggest at least 8 shards per server to keep the storage loads balanced
    # 2 servers: 16 (to enable load balancing)
    # 4 servers: 32 (for better load balancing)
    # 6 servers: 64
    # 8 servers: 128
    # 10 servers: 256
    # 12 servers: 256
    shardCount = 16

    # the cluster will work even if the duplication level is not fulfilled
    # therefore, the duplication level is the maximal duplication at runtime (except during copy operations)
    duplicationLevel = 2

    # relative or absolute file path to a directory (without trailing '/' (separator))
    # vertices and edges of the graph will be stored in files within this directory
    storagePath = "shards"
  }

  clusterlistener {
    create = true
  }

  metricslistener {
    create = true
  }
}
